# HiFi-GAN Vocoder: Отчёт о реализации

## Содержание
1. [Описание модели](#1-описание-модели)
2. [Архитектура](#2-архитектура)
3. [Функции потерь](#3-функции-потерь)
4. [Обработка Mel-спектрограмм](#4-обработка-mel-спектрограмм)
5. [Обучение](#5-обучение)
6. [Результаты](#6-результаты)
7. [Анализ качества вокодера](#7-анализ-качества-вокодера)
8. [Воспроизводимость](#8-воспроизводимость)
9. [Что сработало и что нет](#9-что-сработало-и-что-нет)
10. [Основные сложности](#10-основные-сложности)
11. [Заключение](#11-заключение)

---

## 1. Описание модели

### Выбранная модель: HiFi-GAN V1

HiFi-GAN (High Fidelity Generative Adversarial Network) — это нейросетевой вокодер, предназначенный для синтеза высококачественной речи из mel-спектрограмм. Модель была представлена в статье:

> **HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis**  
> Jungil Kong, Jaehyeon Kim, Jaekyoung Bae (NeurIPS 2020)  
> [arXiv:2010.05646](https://arxiv.org/abs/2010.05646)

### Ключевые особенности HiFi-GAN:

1. **Высокое качество синтеза** — MOS близок к качеству реальной речи
2. **Высокая скорость** — синтез в реальном времени на CPU, ~168x на GPU
3. **Multi-Period Discriminator (MPD)** — захватывает периодические паттерны речи
4. **Multi-Scale Discriminator (MSD)** — моделирует последовательные паттерны
5. **Multi-Receptive Field Fusion (MRF)** — разнообразные рецептивные поля в генераторе

### Почему HiFi-GAN V1?

Выбрана версия V1 как обеспечивающая наивысшее качество синтеза:
- **Скрытая размерность**: 512 (vs 128 в V2 или 256 в V3)
- **Параметры**: ~14M
- **MOS**: 4.36 (из оригинальной статьи)

---

## 2. Архитектура

### 2.1 Generator (Генератор)

Генератор — полностью свёрточная нейронная сеть, которая преобразует mel-спектрограмму во временной сигнал.

```
Mel-спектрограмма (80, T_mel) 
    → Conv1d (80 → 512) 
    → [Upsample + MRF] × 4 
    → Conv1d (32 → 1) 
    → tanh
    → Audio (1, T_audio)
```

**Компоненты генератора:**

| Параметр | Значение | Описание |
|----------|----------|----------|
| `in_channels` | 80 | Количество mel-банд |
| `hidden_channels` | 512 | Скрытая размерность (hu) |
| `upsample_rates` | [8, 8, 2, 2] | Коэффициенты апсемплинга |
| `upsample_kernel_sizes` | [16, 16, 4, 4] | Размеры ядер для ConvTranspose1d |
| `resblock_kernel_sizes` | [3, 7, 11] | Размеры ядер в MRF |
| `resblock_dilations` | [[1,3,5], [1,3,5], [1,3,5]] | Дилатации в residual блоках |

**Апсемплинг:**
```
hop_length = 256 = 8 × 8 × 2 × 2
```

Произведение `upsample_rates` равно `hop_length`, что обеспечивает корректное соотношение между mel-фреймами и аудио-сэмплами.

**Multi-Receptive Field Fusion (MRF):**

MRF модуль объединяет выходы нескольких residual блоков с разными kernel sizes и dilation rates:

```python
class MRF(nn.Module):
    def forward(self, x):
        output = sum(resblock(x) for resblock in self.resblocks)
        return output / len(self.resblocks)
```

Это позволяет модели наблюдать паттерны различной длины параллельно.

### 2.2 Multi-Period Discriminator (MPD)

MPD состоит из 5 под-дискриминаторов с периодами [2, 3, 5, 7, 11] (простые числа для минимизации перекрытий).

**Принцип работы:**
1. 1D аудио (T,) преобразуется в 2D (T/p, p) через reshape
2. Применяются 2D свёртки с ядром (k, 1)
3. Каждый под-дискриминатор обрабатывает только периодические сэмплы

```
Audio (1, T) → Reshape (1, T/p, p) → Conv2d layers → Flatten → Output
```

**Архитектура каждого под-дискриминатора:**
- 5 Conv2d слоёв: 1→32→128→512→1024→1024
- Stride: (3, 1) для первых 4 слоёв
- Kernel: (5, 1)
- Weight normalization
- LeakyReLU (α=0.1)

### 2.3 Multi-Scale Discriminator (MSD)

MSD состоит из 3 под-дискриминаторов, работающих на разных масштабах:
1. Исходное аудио
2. 2x average pooling
3. 4x average pooling

**Архитектура каждого под-дискриминатора:**
- 7 Conv1d слоёв с grouped convolutions
- Увеличение каналов: 1→128→256→512→1024→1024→1024
- Первый под-дискриминатор: Spectral Normalization
- Остальные: Weight Normalization

---

## 3. Функции потерь

HiFi-GAN использует комбинацию нескольких функций потерь:

### 3.1 Adversarial Loss (LS-GAN)

Используется Least Squares GAN для стабильного обучения:

**Дискриминатор:**
```
L_D = E[(D(x) - 1)² + D(G(s))²]
```

**Генератор:**
```
L_Adv(G) = E[(D(G(s)) - 1)²]
```

### 3.2 Mel-Spectrogram Loss

L1 расстояние между mel-спектрограммами реального и сгенерированного аудио:

```
L_Mel = ||φ(x) - φ(G(s))||₁
```

где φ — функция извлечения mel-спектрограммы.

**Назначение:** 
- Ускоряет обучение генератора
- Стабилизирует adversarial training
- Улучшает перцептивное качество

### 3.3 Feature Matching Loss

L1 расстояние между промежуточными признаками дискриминатора:

```
L_FM = Σᵢ (1/Nᵢ) × ||Dᵢ(x) - Dᵢ(G(s))||₁
```

**Назначение:** Обучение генератора на основе learned similarity metric.

### 3.4 Итоговые функции потерь

**Генератор:**
```
L_G = L_Adv(G; MPD) + L_Adv(G; MSD) + 
      λ_fm × (L_FM(G; MPD) + L_FM(G; MSD)) + 
      λ_mel × L_Mel(G)
```

**Дискриминатор:**
```
L_D = L_Adv(D_MPD; G) + L_Adv(D_MSD; G)
```

**Гиперпараметры (из статьи):**
- λ_fm = 2
- λ_mel = 45

---

## 4. Обработка Mel-спектрограмм

### 4.1 Конфигурация

| Параметр | Значение | Описание |
|----------|----------|----------|
| Sample Rate | 22050 Hz | RUSLAN ресемплирован с 44100 Hz |
| n_fft | 1024 | Размер FFT |
| win_length | 1024 | Длина окна |
| hop_length | 256 | Шаг окна |
| n_mels | 80 | Количество mel-банд |
| f_min | 0 Hz | Минимальная частота |
| f_max | 8000 Hz | Максимальная частота |

### 4.2 Процесс извлечения

```python
# 1. Вычисление mel-спектрограммы
mel = torchaudio.transforms.MelSpectrogram(...)(audio)

# 2. Логарифмическое масштабирование
mel = torch.log(torch.clamp(mel, min=1e-5))
```

### 4.3 Ресемплирование RUSLAN

Датасет RUSLAN записан с частотой 44100 Hz. Для обучения выполняется ресемплирование до 22050 Hz:
- Стандарт для TTS
- Меньше вычислительных затрат
- Совместимость с большинством предобученных моделей

---

## 5. Обучение

### 5.1 Оптимизация

| Параметр | Значение |
|----------|----------|
| Optimizer | AdamW |
| β₁, β₂ | 0.8, 0.99 |
| Weight Decay | 0.01 |
| Learning Rate | 2×10⁻⁴ |
| LR Scheduler | ExponentialLR (γ=0.999) |

### 5.2 Параметры обучения

| Параметр | Значение |
|----------|----------|
| Batch Size | 16 |
| Segment Size | 8192 сэмплов (~0.37 с) |
| Gradient Clipping | Включён |
| Early Stopping | По val mel loss |

### 5.3 Аугментации

- Случайная обрезка аудио до segment_size
- Нормализация аудио

### 5.4 Логирование

Все метрики и аудио-сэмплы логируются в CometML:
- [https://www.comet.com/krugd/hifigan-russian-tts](https://www.comet.com/krugd/hifigan-russian-tts/444cc4e3c69c439cbd2f2186e108e03c?compareXAxis=step&experiment-tab=panels&showOutliers=true&smoothing=0&viewId=new&xAxis=step)

**Логируемые метрики:**
- `loss_gen_total` — полный лосс генератора
- `loss_disc` — лосс дискриминатора
- `loss_mel` — mel-spectrogram loss
- `loss_fm` — feature matching loss
- `loss_gen_mpd`, `loss_gen_msd` — adversarial loss по дискриминаторам
- `val_loss_mel` — валидационный mel loss

**Логируемые артефакты:**
- Аудио: ground truth vs generated
- Спектрограммы: input mel vs generated mel

---

## 6. Результаты

### 6.1 Логи обучения

Обучение проводилось на датасете RUSLAN. Ключевые наблюдения из логов:

1. **Mel loss** быстро падает в первые эпохи и стабилизируется
2. **Adversarial loss** колеблется, что характерно для GAN
3. **Feature matching loss** помогает стабилизировать обучение

### 6.2 Качество синтеза

- Синтезированное аудио звучит натурально
- Минимальные артефакты
- Хорошее воспроизведение интонации и тембра

### 6.3 Скорость инференса

На GPU (NVIDIA):
- ~100-200x быстрее реального времени

На CPU:
- Синтез в реальном времени возможен

---

## 7. Анализ качества вокодера

> Детальный анализ проведён в ноутбуке [analysis.ipynb](./analysis.ipynb)

### 7.1 Анализ на обучающих данных (RUSLAN)

**Методология:**
- Взято 15-20 аудиозаписей из тестового сета RUSLAN
- Извлечены mel-спектрограммы из ground-truth аудио
- Сгенерированы синтезированные версии через HiFi-GAN (resynthesize)
- Проведено сравнение во временной и частотно-временной областях

**Наблюдения:**

| Аспект | Оригинал vs Синтезированное |
|--------|---------------------------|
| Waveform | Различия минимальны, небольшие отличия на концах |
| Mel-спектрограмма | Практически идентичны |
| На слух | Небольшие шумы в сгенерированном аудио |

**Количественные метрики:**
- **Mel L1 Distance**: 0.2680 +/- 0.0100

**Ответы на вопросы:**

1. **Какие различия вы видите?**
   
   Различий практически нет, только небольшие на концах waveform.

2. **Можно ли на слух понять, что аудио синтезировано?**
   
   У сгенерированного аудио есть небольшие шумы. Если не слушать оригинал, то невозможно.

3. **Можно ли это определить по форме волны или спектрограмме?**
   
   Можно по концам waveform в некоторых участках.

4. **Какие выводы вы можете сделать?**
   
   Модель обучилась довольно хорошо, сгенерированное аудио от реального отличить практически невозможно.

### 7.2 Анализ на внешних данных

**Методология:**
- Использованы 5 аудиозаписей, сгенерированных Silero TTS для тестовых предложений
- Применена аналогичная процедура resynthesize
- Сравнение с результатами на обучающих данных

**Тестовые предложения:**
1. "Привет, это тест системы синтеза речи."
2. "Нейронные сети генерируют реалистичную речь."
3. "Качество звука постоянно улучшается."
4. "Добрый день, как ваши дела?"
5. "Сегодня прекрасная погода для прогулки."

**Количественные метрики:**
- **Mel L1 Distance**: 0.4226 +/- 0.1619

**Сравнение RUSLAN vs External:**

| Метрика | RUSLAN | External | Разница |
|---------|--------|----------|---------|
| Mel L1 Mean | 0.2680 | 0.4226 | +58% |
| Mel L1 Std | 0.0100 | 0.1619 | +16x |

**Ответы на вопросы:**

1. **Справедливы ли выводы из анализа на обучающих данных?**
   
   Частично. На RUSLAN модель показывает стабильно низкую ошибку (0.27), на external данных ошибка выше (0.42). Качество синтеза все равно приемлемое.

2. **Какие различия вы видите между обучающим и внешним датасетами?**
   
   External имеет на 58% выше Mel L1 и в 16 раз выше дисперсию. Модель менее стабильна на unseen данных.

3. **Объясните причины различий, если они есть**
   
   - Модель обучалась на RUSLAN (один спикер, определенные акустические условия)
   - External данные (Silero TTS) имеют другой голос, интонацию, акустику
   - Это типичное поведение domain gap - модель лучше работает на данных, похожих на обучающие

### 7.3 Full TTS System Analysis

**Статус:** Данный раздел пропущен (опционален согласно заданию).

**Причина:** Конфликты зависимостей при установке акустических моделей (ESPnet, NeMo) не позволили выполнить полный TTS pipeline.

**Альтернатива:** Для оценки работы вокодера на unseen данных использовались аудиофайлы, сгенерированные Silero TTS (см. раздел 7.2). Результаты показали хорошую генерализацию вокодера (Mel L1 = 0.42 на external vs 0.27 на RUSLAN).

### 7.4 Количественные метрики

| Dataset | N Samples | Mel L1 Mean | Mel L1 Std |
|---------|-----------|-------------|------------|
| RUSLAN  | 20        | 0.2680      | 0.0100     |
| External| 5         | 0.4226      | 0.1619     |

### 7.5 Финальные выводы

**Общие наблюдения о качестве синтезированных образцов:**
- Модель HiFi-GAN V1 обеспечивает высокое качество синтеза на обучающих данных
- Mel L1 Distance на RUSLAN составляет 0.27, что свидетельствует о точном воспроизведении спектральных характеристик
- На внешних данных качество несколько снижается (Mel L1 = 0.42), но остается приемлемым

**Легкость обнаружения синтезированного аудио:**
- На обучающих данных: практически невозможно отличить на слух без сравнения с оригиналом
- На внешних данных: небольшие артефакты могут быть заметны, но общее качество остается высоким

**Ограничения системы:**
- Domain gap: модель лучше работает на данных, похожих на обучающие
- Вариативность: более высокая дисперсия на unseen данных (0.16 vs 0.01)
- Границы сегментов: небольшие артефакты на концах waveform

**Рекомендации по улучшению:**
- Fine-tuning на разнообразных данных для лучшей генерализации
- Аугментация данных при обучении
- Использование архитектурных улучшений (Snake activation из BigVGAN)

---

## 8. Воспроизводимость

### 7.1 Требования

```bash
# Клонирование репозитория
git clone https://github.com/KrugD/HW3_TTS.git
cd HW3_TTS

# Установка зависимостей
pip install -r requirements.txt
```

### 7.2 Скачивание весов

```bash
python download_weights.py
```

Веса также доступны напрямую: [Google Drive](https://drive.google.com/file/d/1LTl3m5ZScfefGvQUXTBAYfBeoSKhDZR2/view?usp=sharing)

### 7.3 Инференс

**Resynthesize режим** (из ground-truth аудио):
```bash
python synthesize.py \
    input_dir=path/to/audio \
    output_dir=output/synthesized \
    checkpoint=models_weights/generator_best.pt \
    resynthesize=true
```

**Inference режим** (из mel-спектрограмм акустической модели):
```bash
python synthesize.py \
    input_dir=path/to/audio \
    output_dir=output/synthesized \
    checkpoint=models_weights/generator_best.pt \
    resynthesize=false
```

### 7.4 Обучение с нуля

```bash
# Скачивание датасета RUSLAN
python download_ruslan.py

# Запуск обучения
python train.py
```

### 7.5 Demo Notebook

Для быстрого ознакомления с моделью предоставлен `demo.ipynb`, который:
1. Клонирует репозиторий
2. Устанавливает зависимости
3. Скачивает веса
4. Демонстрирует синтез аудио
5. Работает в Google Colab

---

## 9. Что сработало и что нет

### Что сработало:

1. **Архитектура из оригинальной статьи** — V1 конфигурация даёт отличные результаты
2. **Weight Normalization** — стабилизирует обучение генератора
3. **Spectral Normalization для первого MSD** — улучшает качество
4. **Mel-spectrogram loss с λ=45** — ключевой компонент для качества
5. **Периоды [2,3,5,7,11] для MPD** — простые числа минимизируют перекрытия
6. **AdamW optimizer** — лучше чем Adam с L2 регуляризацией
7. **Early stopping по val mel loss** — предотвращает переобучение

### Что потребовало настройки:

1. **Batch size** — пришлось уменьшить из-за ограничений GPU памяти
2. **Segment size** — баланс между контекстом и памятью
3. **Learning rate** — 2×10⁻⁴ оптимально, больше — нестабильность

### Что не сработало / не применялось:

1. **Noise injection в генератор** — как и в статье, не используется
2. **Очень большие batch sizes** — ограничения памяти

---

## 10. Основные сложности

### 9.1 Память GPU

**Проблема:** HiFi-GAN требует значительного объёма GPU памяти, особенно:
- Генератор с hu=512
- Два дискриминатора (MPD + MSD)
- Feature maps для feature matching loss

**Решение:**
- Уменьшение batch size

### 9.2 Стабильность GAN обучения

**Проблема:** Баланс между генератором и дискриминатором

**Решение:**
- Mel-spectrogram loss стабилизирует обучение
- Feature matching loss как дополнительный supervision
- Правильные веса λ_fm=2, λ_mel=45

### 9.3 Длина аудио

**Проблема:** Различные длины аудио в батче

**Решение:**
- Случайная обрезка до фиксированного segment_size
- Padding для инференса
- Обрезка до минимальной длины при сравнении

### 9.4 Совместимость mel-спектрограмм

**Проблема:** Важно использовать одинаковую конфигурацию mel для обучения и инференса

**Решение:**
- Единый `MelSpectrogramConfig` во всех модулях
- Конфигурация через Hydra

### 9.5 Ресемплирование

**Проблема:** RUSLAN записан на 44100 Hz, стандарт TTS — 22050 Hz

**Решение:**
- Ресемплирование на лету в датасете
- Использование torchaudio.transforms.Resample

---

## 11. Заключение

В рамках данного домашнего задания была успешно реализована модель HiFi-GAN V1 для синтеза русской речи на датасете RUSLAN.

### Основные достижения:

1. Полная реализация архитектуры HiFi-GAN V1
2. Multi-Period Discriminator с периодами [2, 3, 5, 7, 11]
3. Multi-Scale Discriminator с 3 масштабами
4. Multi-Receptive Field Fusion в генераторе
5. Все функции потерь: Adversarial, Feature Matching, Mel-spectrogram
6. Обучение на RUSLAN с логированием в CometML
7. Скрипты для инференса и demo notebook

### Ссылки:

- **Репозиторий:** https://github.com/KrugD/HW3_TTS
- **CometML логи:** [https://www.comet.com/krugd/hifigan-russian-tts](https://www.comet.com/krugd/hifigan-russian-tts/444cc4e3c69c439cbd2f2186e108e03c)
- **Веса модели:** [Google Drive](https://drive.google.com/file/d/1LTl3m5ZScfefGvQUXTBAYfBeoSKhDZR2/view?usp=sharing)

---

## Приложения

### A. Количество параметров

| Компонент | Параметры |
|-----------|-----------|
| Generator (V1) | ~13.9M |
| MPD | ~5M |
| MSD | ~10M |
| **Итого** | ~29M |

### B. Структура проекта

```
HW3_TTS/
├── src/
│   ├── configs/           # Hydra конфигурации
│   ├── datasets/          # RUSLAN и CustomDir датасеты
│   ├── model/             # Generator, MPD, MSD
│   ├── loss/              # HiFi-GAN losses
│   ├── transforms/        # Mel-spectrogram
│   ├── trainer/           # Training loop
│   ├── logger/            # CometML logger
│   └── utils/             # Utilities
├── train.py               # Скрипт обучения
├── synthesize.py          # Скрипт синтеза
├── download_weights.py    # Скачивание весов
├── download_ruslan.py     # Скачивание датасета
├── demo.ipynb             # Demo notebook
├── requirements.txt       # Зависимости
├── README.md              # Документация
└── REPORT.md              # Этот отчёт
```

### C. Гиперпараметры обучения

```yaml
# Optimizer
optimizer: AdamW
lr: 0.0002
betas: [0.8, 0.99]
weight_decay: 0.01

# Scheduler
scheduler: ExponentialLR
gamma: 0.999

# Loss weights
lambda_fm: 2
lambda_mel: 45

# Training
batch_size: 16
segment_size: 8192
n_epochs: 100
early_stopping_patience: 10
```
